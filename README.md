### __Course Structure__ 

- Central Limit theurom and its importance
- Sampling and its types
- Expectation, Variance and Mean
- Error analysis
- Bias and variance and its trade-off
- linear/non-lineer/multiple/logistic regression , assumptions, performance metrics
- R-value, Adjusted-R, P-value
- L1 and L2, ridge and lasso
- Decision tree(CART, ID3.4)
- Bagging, Boosting , Stacking, (why bagging works)
- Underfitting and Overfitting, Tradeoff, overcoming them , preventive methods
- Random Forest
- Adaboost, Gradient Boost, XGboost etc.
- Perceptron model, Activation function, Neural network/cnn, Backpropagation, Grad descent/asscent
- Effect of Batch size, learning rate.
- Loss function/ optimization/ how to derive them
- SVM and assumptions
- conditional probability, conditional idependence
- Naive bayes and assumption
- Confusion Matrix, AUC, ROC, false positive, false negative, etc.
- Performance metrics in CNN (mAP, confusion matrix etc.)
- K- nearest neighbour, Assumption, Performance metrics, Advantages and Disadvantages.
- K- mean, Assumption, Performance metrics, Advantages and Disadvantages.
- DSBCAN and Other clustering algorithm
- Gaussian mixture model
- Expectation maximization

### __License ans Citatation__
If you are using this repo for prepration and in some work, and it helped you in anyway, please consider dropping a mail to me or cite this repo with link in any of your repo and follow me on github.
